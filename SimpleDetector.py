"""
æç®€å°ç›®æ ‡æ£€æµ‹æ¨¡å‹ - åŸºäºDINOv3
å»é™¤æ‰€æœ‰å¤æ‚æœºåˆ¶ï¼Œåªä¿ç•™æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.ops import nms
import numpy as np
import config


class SimpleDetectionHead(nn.Module):
    """æç®€æ£€æµ‹å¤´ - æ— anchorï¼Œç›´æ¥é¢„æµ‹"""

    def __init__(self, in_channels=256, num_classes=2):
        super().__init__()
        self.num_classes = num_classes

        # å…±äº«ç‰¹å¾æå–
        self.shared = nn.Sequential(
            nn.Conv2d(in_channels, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )

        # åˆ†ç±»åˆ†æ”¯ï¼šæ¯ä¸ªä½ç½®é¢„æµ‹num_classesä¸ªåˆ†æ•°
        self.cls_head = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, num_classes, 1)
        )

        # å›å½’åˆ†æ”¯ï¼šæ¯ä¸ªä½ç½®é¢„æµ‹4ä¸ªå€¼ [x_offset, y_offset, w, h]
        self.reg_head = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 4, 1)
        )

        self._init_weights()

    def _init_weights(self):
        """ç®€å•çš„åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight, std=0.01)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

        # åˆ†ç±»å¤´çš„biasåˆå§‹åŒ–ä¸ºè´Ÿå€¼ï¼Œè®©åˆå§‹é¢„æµ‹å€¾å‘äºèƒŒæ™¯
        bias_value = -np.log(9)
        nn.init.constant_(self.cls_head[-1].bias, bias_value)

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        feat = self.shared(x)
        cls_pred = self.cls_head(feat)
        reg_pred = self.reg_head(feat)
        return cls_pred, reg_pred


class SimpleDetector(nn.Module):
    """å®Œæ•´çš„ç®€å•æ£€æµ‹å™¨"""

    def __init__(self, dinov3_backbone, num_classes=2, freeze_backbone=True,
                 img_size=640, stride=16):
        super().__init__()
        self.backbone = dinov3_backbone
        self.num_classes = num_classes
        self.img_size = img_size
        self.stride = stride

        # å†»ç»“backbone
        if freeze_backbone:
            for param in self.backbone.parameters():
                param.requires_grad = False

        # DINOv3è¾“å‡ºæ˜¯1024ç»´
        backbone_dim = 1024

        # ç‰¹å¾æŠ•å½±ï¼š1024 -> 256
        self.proj = nn.Sequential(
            nn.Conv2d(backbone_dim, 512, 1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 256, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )

        # æ£€æµ‹å¤´
        self.head = SimpleDetectionHead(in_channels=256, num_classes=num_classes)

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        B = x.size(0)

        # æå–DINOv3ç‰¹å¾
        if not self.training:
            with torch.no_grad():
                features_dict = self.backbone.forward_features(x)
        else:
            features_dict = self.backbone.forward_features(x)

        # è·å–patch tokenså¹¶é‡å¡‘
        patch_tokens = features_dict['x_norm_patchtokens']
        B, num_patches, C = patch_tokens.shape
        H = W = int(num_patches ** 0.5)

        features = patch_tokens.reshape(B, H, W, C).permute(0, 3, 1, 2)

        # ç‰¹å¾æŠ•å½±
        features = self.proj(features)

        # æ£€æµ‹å¤´
        cls_pred, reg_pred = self.head(features)

        return cls_pred, reg_pred

    def decode_predictions(self, cls_pred, reg_pred, conf_threshold=0.05, nms_threshold=0.5):
        """è§£ç é¢„æµ‹ç»“æœ"""
        B, C, H, W = cls_pred.shape
        device = cls_pred.device

        results = []

        for b in range(B):
            cls_scores = torch.sigmoid(cls_pred[b])
            reg_b = reg_pred[b]

            # ç”Ÿæˆåæ ‡ç½‘æ ¼
            y_indices, x_indices = torch.meshgrid(
                torch.arange(H, device=device),
                torch.arange(W, device=device),
                indexing='ij'
            )

            x_centers = (x_indices.float() + 0.5) * self.stride
            y_centers = (y_indices.float() + 0.5) * self.stride

            # Flatten
            cls_flat = cls_scores.reshape(C, -1).permute(1, 0)
            reg_flat = reg_b.reshape(4, -1).permute(1, 0)
            x_centers_flat = x_centers.reshape(-1)
            y_centers_flat = y_centers.reshape(-1)

            max_scores, labels = cls_flat.max(dim=1)

            # ç½®ä¿¡åº¦è¿‡æ»¤
            keep = max_scores > conf_threshold
            if not keep.any():
                results.append({
                    'boxes': torch.zeros((0, 4), device=device),
                    'scores': torch.zeros((0,), device=device),
                    'labels': torch.zeros((0,), dtype=torch.long, device=device)
                })
                continue

            scores = max_scores[keep]
            labels = labels[keep]
            reg_keep = reg_flat[keep]
            x_centers_keep = x_centers_flat[keep]
            y_centers_keep = y_centers_flat[keep]

            # è§£ç bbox
            dx = reg_keep[:, 0]
            dy = reg_keep[:, 1]
            w = torch.exp(reg_keep[:, 2].clamp(min=-10, max=10))
            h = torch.exp(reg_keep[:, 3].clamp(min=-10, max=10))

            cx = x_centers_keep + dx * self.stride
            cy = y_centers_keep + dy * self.stride

            x1 = cx - w / 2
            y1 = cy - h / 2
            x2 = cx + w / 2
            y2 = cy + h / 2

            boxes = torch.stack([x1, y1, x2, y2], dim=1)

            boxes[:, 0::2].clamp_(min=0, max=self.img_size)
            boxes[:, 1::2].clamp_(min=0, max=self.img_size)

            # è¿‡æ»¤æ— æ•ˆæ¡†
            widths = boxes[:, 2] - boxes[:, 0]
            heights = boxes[:, 3] - boxes[:, 1]
            valid = (widths > 1) & (heights > 1)

            boxes = boxes[valid]
            scores = scores[valid]
            labels = labels[valid]

            # NMS
            keep_nms = []
            for cls_id in range(self.num_classes):
                cls_mask = labels == cls_id
                if not cls_mask.any():
                    continue

                cls_boxes = boxes[cls_mask]
                cls_scores = scores[cls_mask]

                keep_cls = nms(cls_boxes, cls_scores, nms_threshold)
                keep_nms.append(torch.where(cls_mask)[0][keep_cls])

            if keep_nms:
                keep_nms = torch.cat(keep_nms)
                boxes = boxes[keep_nms]
                scores = scores[keep_nms]
                labels = labels[keep_nms]
            else:
                boxes = torch.zeros((0, 4), device=device)
                scores = torch.zeros((0,), device=device)
                labels = torch.zeros((0,), dtype=torch.long, device=device)

            results.append({
                'boxes': boxes,
                'scores': scores,
                'labels': labels
            })

        return results


def get_model():
    """åŠ è½½æ¨¡å‹ - åŒ…å«backboneå’Œæƒé‡"""
    print("ğŸš€ åˆå§‹åŒ–æ¨¡å‹...")
    
    # åŠ è½½backbone
    dinov3_backbone = torch.hub.load(
        config.REPO_DIR, 'dinov3_vitl16',
        source='local',
        weights=config.BACKBONE_WEIGHTS
    )
    
    # æ„å»ºæ£€æµ‹å™¨
    model = SimpleDetector(
        dinov3_backbone=dinov3_backbone,
        num_classes=config.NUM_CLASSES,
        freeze_backbone=config.FREEZE_BACKBONE,
        img_size=config.IMG_SIZE,
        stride=config.STRIDE
    )
    
    # åŠ è½½æƒé‡
    device = torch.device(config.DEVICE)
    print(f"  â”œâ”€ åŠ è½½æƒé‡: {config.HEAD_WEIGHTS}")
    
    try:
        checkpoint = torch.load(config.HEAD_WEIGHTS, map_location=device, weights_only=False)
    except RuntimeError:
        checkpoint = torch.load(config.HEAD_WEIGHTS, map_location=device)
    
    # è·å–state_dict
    if 'model' in checkpoint:
        state_dict = checkpoint['model']
    elif 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    elif 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    # å»é™¤module.å‰ç¼€
    new_state_dict = {}
    for k, v in state_dict.items():
        new_state_dict[k.replace('module.', '')] = v
    
    model.load_state_dict(new_state_dict, strict=False)
    model.to(device)
    model.eval()
    
    print("  â””â”€ âœ“ æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    return model